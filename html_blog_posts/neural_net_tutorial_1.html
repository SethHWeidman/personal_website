<!DOCTYPE html>
<html lang="en">

<head>

    <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'>
    MathJax.Hub.Config({
  tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]}});</script>
</head>
<body>

                  <p>You're probably here because you're interested in Neural Nets and Deep Learning, but
                    nothing you've read so far has provided a comprehensive understanding of both
                    <em>how</em> and <em>why</em> they work. You may have even written some lines of code
                    using libraries like TensorFlow or Keras that caused some quite amazing things to
                    happen that you nevertheless didn't fully understand. If you're here, that means
                    that you're the kind of person where that bothered you - you wanted to understand
                    both <em>what</em> was actually happening and <em>why</em> it was working
                    (two separate but individually very important questions).</p>

                    <p>This series of blog posts is for you. It is intended to be careful, thorough
                      explanation of how neural nets work from first principles. I will use math
                      in this blog post and others: understanding of the basics of the concept of
                      derivatives from calculus is necessary, and I intend to write a supplemental
                      "refresher" on derivatives down the line. The goal will be that, after
                      understanding these basic first principles, you will be able to understand
                      much more complex concepts in Deep Learning, since in most cases they are
                      simply the basic principles combined together in different ways.</p>

                      <p>Let's begin.</p>
                      <p>--</p>
                      <p>There are two things you need to know to understand neural nets: you need
                        to know <em>what</em> they are doing and <em>why</em> what they are doing works.</p>

                        <p>Typically, tutorials on neural nets start by defining them in terms of drawings like this:</p>
                        <p><img src="https://i.stack.imgur.com/9jzpy.jpg" /></p>
                        <p>This is, in my view, a great way to make neural nets look like something complicated and
                          impressive but a terrible way to introduce people to them. This drawing provides insight
                          <em>neither</em> into how neural nets work - e.g. the actual computations performed during
                          "learning" - <em>nor</em> into <em>why</em> they work.</p>

                          <p>These kinds of drawings will be important much later, when we describe neural nets with
                            many "layers" (another term that should not be introduced too early).</p>

                          <p>How should we think of neural nets then?</p>

                          <p>Simple: recall that in linear regression, or other basic predictive problems, the outputs are modeled as a simple function of the inputs, and some parameters. In the language of neural nets, these parameters are called weights, so here I'll call then weights.</p>

                          <p>For example, we will write a model $M$ as</p>

                          $$M(x_1, ..., x_n, \beta_1, ... , \beta_n) = x_1 * \beta_1 + ... + x_n * \beta_n$$

                          <p>and then, for given values of $\beta_1, ... , \beta_n$, resulting in an output $M$,
                            compute the loss L as a function of this prediction $M$ simply by taking the difference
                            between $M$ and the actual value of the prediction $y$:</p>

                          $$L = \frac{1}{2}(M - y)^2$$

                          <p>Finally, we can do the standard computation involved in gradient descent, computing:</p>

                          $$\frac{\partial L}{\partial \beta_1} , ... , \frac{\partial L}{\partial \beta_n}$$

                          <p> to figure out whether we need to increase or decrease each $\beta$ to
                            reduce the loss. (In the future, I will write a separate blog post on that;
                            stay tuned)</p>

                          <p>How are neural nets different than this? We know that, at a high level, they are more
                            complicated versions of simple regression. But how, specifically, are they more complicated?</p>

                            <p>Simple: rather than just computing a function of the output in terms of the input and some
                              parameters, $F(X,B)$, <strong>neural nets are <em>nested</em> functions</strong>, so that instead
                              we would compute $G(F(X,B))$ for example.</p>

                          <p>From this simple definition, you can begin to understand:</p>
                          <ul>
                          <li>Why neural nets&nbsp;can be infinitely more complicated than simpler models.</li>
                          <li><em>Why</em> we must modify the gradient descent procedure to account for this added complexity.</li>
                          <li><em>How</em>&nbsp;we must modify&nbsp;the gradient descent procedure to account for this added complexity.</li>
                          </ul>

                          <p>So, now we get to it: let's make this linear regression example one "step" more
                            complicated and walk through and example in detail:</p>

                            <p>Let's consider a neural net that in fact just consists of two nested functions:
                              the first calculates a linear combination of the inputs with some weights, and
                              the second applies a sigmoid to this.</p>

                            <p>Again, for simplicity's sake, we'll assume that we start with three inputs.</p>

                          <p>A verbal description of the net would be:<br/>"We are going to take in three features,
                            which we will call $ X $, take a linear combination of those features with weights $ W $,
                            then take the sigmoid of those features, and that will be our prediction $ P $."</p>

                            <p>Note: recall that the sigmoid function is:</p>

                              $$ \sigma(x) = \frac{1}{1 + e^{-x}} $$

                          <p>A mathematical description of this is:
                            <br />$$ A = X_1 * W_1 + X_2 * W_2 + X_3 * W_3 $$
                            $$ P = \sigma(A) $$
                            </p>

                            We then compute the loss $ L $ in terms of $ P $. We'll use squared loss but
                            this choice is arbitrary. If the "target" we are trying to predict is $ y $,
                            then:$$ L(P) = \frac{1}{2}(y - P)^2 $$

                            <p>We can think of this neural net in terms of function composition:</p>

                            <ul>
                            <li>We start with input $ X $, which is really a vector
                              $\begin{bmatrix}x_1 & x_2 & x_3\end{bmatrix}$
                            <li>We apply one function to this vector, call it $ A(X) $, that has three parameters,
                              $ w1 $, $ w2 $, and $ w3 $. $ A(X) $ returns 1 number, even though it took in 3
                              numbers as arguments. Note a general point, illustrated here, that will be
                              important later: <em>functions with parameters can output a different number
                              of numbers than they input.</em></li>
                            <li>We then apply another function to $ A(X) $ called $ B $, where $ B $ is the sigmoid function.
                              There is a key difference here: unlike $ A $, $ B $ takes in no parameters. This too will
                              be important later.</li>
                            <li>Our final prediction $ P $, then, would be $ B(A(X)) $, in this representation.</li>
                            <li>Finally, our loss will be $ L(P(B(A(X)))) $.</li>
                          </ul>

                            <p>How would we code this? Well, we can make $ X $ a 1 x 3 matrix - everything could be
                              transposed, but ultimately we'll want to "stack" observations on top of each other
                              as rows, so we'll make $ X $ a 1 x 3.</p>

                              <pre class="brush: python">
                                import numpy as np
                                X = np.array([ [0,0,1] ])
                                </pre>

                            <p>$ y $ will, for obvious reasons, be a 1 x 1 matrix</p>

                              <pre class="brush: python">
                                y = np.array([ [1] ])
                                </pre>

                            <p>I will completely sidestep the very important topic of how to initialize our weights,
                              and just say here that we’ll initialize them to be mean 0 and standard deviation 1.</p>

                            <pre class="brush: python">
                              W = np.random.randn(3, 1)
                            </pre>

                            <p>Now, we’ll compute $ A $, the linear combination of those weights
                              with the inputs $ X $. We’ll do this using the syntax of matrix multiplication.</p>

                              <pre class="brush: python">
                                A = np.dot(X,W)
                              </pre>

                              <p>This is now just a number. Now, we’ll take that $ A $ and
                              apply a sigmoid function to it, getting $ P $.</p>

                              <pre class="brush: python">
                                P = \sigma(A)
                              </pre>

                              <p>Finally, we’ll compute the squared loss, $ L $, which will
                                itself be a function of $ P $.</p>

                                <pre class="brush: python">
                                  L = 0.5 * ( y - P ) ** 2
                                </pre>

                            <p>Now, here&rsquo;s the question we have to answer - answering this
                              question will determine how well neural nets will work.</p>
                            <p>~~How can we update the weight vector W to reduce this loss?~~</p>

                            <p>We know that the steps,&nbsp;at a high level are:</p>

                            <ol>
                            <li>Compute $ \frac{\partial L}{\partial W} $, or the amount that the loss changes as the weights change.</li>
                            <li>Subtract some a learning rate times this loss from W. So that if
                              increasing the weights will cause the loss to <em>increase</em>, so
                              that dLdW is positive, then W will <em>decrease</em> so that the
                              loss decreases.</li>
                            </ol>

                        <p>The question then becomes: in this slightly more complicated context
                          that linear regression, how do we compute $ \frac{\partial L}{\partial W} $.</p>

                          <p>The answer is that we have to use the chain rule from calculus.
                            To see how this will work - and this is the beauty of describing
                            neural nets as nested functions - note that as we've defined
                            things above,</p>

                        $$ L(W) = L(P(B(A(W)))) $$

                        <p>Therefore, $ \frac{\partial L}{\partial W} $ is the product of three quantities:</p>
                        <ol>
                        <li>$ \frac{\partial L}{\partial P} $</li>
                        <li>$ \frac{\partial P}{\partial A} $</li>
                        <li>$ \frac{\partial A}{\partial W} $</li>
                        </ol>

                      <p>This all may look complicated, considered together. Nevertheless,
                        each of these quantities can be computed rather simply.</p>

                      <p>Indeed, the first of these is:</p>

                      $$ \frac{\partial L}{\partial P} = -1 * (y - P) $$

                      <p>We can code this as:</p>

                      <pre class="brush: python">
                      dLdP = -1.0 * (y - P)
                    </pre>

                    <p>The second of these is:</p>

                    $$ \frac{\partial P}{\partial A} = \sigma(A) * (1 - \sigma(A)) $$

                    <p>We can code this as:</p>

                  <pre class="brush: python">
                    dHdA = sigmoid(A) * (1.0 - sigmoid(A))
                  </pre>

                  <p>Finally, using the chain rule, we can write:</p>

                  $$ \frac{\partial L}{\partial A} = \frac{\partial L}{\partial P} * \frac{\partial P}{\partial A}  $$

                  <p>And in code:</p>

                  <pre class="brush: python">
                  dLdA = dLdH * dHdA
                  </pre>

                  <p>The third is slightly trickier, but not by much. Recall that when we say $ \frac{\partial L}{\partial W} $
                    we are really separately computing $ \frac{\partial L}{\partial W_1} $,
                    $ \frac{\partial L}{\partial W_2} $, and $ \frac{\partial L}{\partial W_3} $. And since </p>

                    $$ A = X_1 * W_1 + X_2 * W_2 + X_3 * W_3 $$

                    <p> we can compute:</p>

                    $$ \frac{\partial A}{\partial W_1} = X_1 $$
                    $$ \frac{\partial A}{\partial W_2} = X_2 $$
                    $$ \frac{\partial A}{\partial W_3} = X_3 $$

                    <p>Now for a cool trick. Since</p>

                    $$ W=\begin{bmatrix}
                        W_1 \\
                        W_2 \\
                        W_3\\
                       \end{bmatrix} $$

                      <p>and</p>

                      $$ X=\begin{bmatrix}
                          X_1 & X_2 & X_3
                         \end{bmatrix} $$

                     <p>We can write, as shorthand for the above three equations:</p>

                     $$ \frac{\partial A}{\partial W} = X^T $$

                    <p> And in code, we can write this as:</p>

                  <pre class="brush: python">
                    dAdW = X.T
                  </pre>

                    <p>So, putting these three pieces together:</p>

                    $$ \frac{\partial L}{\partial W_1} = \frac{\partial L}{\partial P} * \frac{\partial P}{\partial A} * \frac{\partial A}{\partial W_1} $$
                    $$ \frac{\partial L}{\partial W_2} = \frac{\partial L}{\partial P} * \frac{\partial P}{\partial A} * \frac{\partial A}{\partial W_2} $$
                    $$ \frac{\partial L}{\partial W_3} = \frac{\partial L}{\partial P} * \frac{\partial P}{\partial A} * \frac{\partial A}{\partial W_3} $$

                    <p>Or, more generally:</p>
                    $$ \frac{\partial L}{\partial W_i} = \frac{\partial L}{\partial P} * \frac{\partial P}{\partial A} * \frac{\partial A}{\partial W_i} $$

                    <p>Since we have computed these first two pieces, we can write:</p>

                    $$ \frac{\partial L}{\partial W_i} = -1.0 * (y - P) * \sigma(A) * (1.0 - \sigma(A)) * X_i $$

                    <p>In code, taking advantage of the two quantities we have already computed and using the
                      matrix multiplication shorthand (which will come in handy later), we can write:</p>

                  <pre class="brush: python">
                      dLdW = np.dot(dAdW, dLdA)
                  </pre>

                  <p>To understand why this matrix multiplication "makes sense" remember that $ X $ is a 1 x 3 matrix,
                    so $ X^T $ is a 3 x 1 matrix - the same dimensions as $ W $, and $ \frac{\partial A}{\partial W} $,
                    the product of $ \frac{\partial L}{\partial P} $ and $ \frac{\partial P}{\partial A} $,  is a 1 x 1 matrix.</p>

                    <p>Finally, we actually make an update. We’ll choose an arbitrary learning rate of 0.5</p>

                    <pre class="brush: python">
                        W -= 0.5 * dLdW
                    </pre>

                    <p>And there you have it. You have properly coded - and understood at each step why you were coding
                      - all the steps of a backpropogation algorithm.</p>

                    Putting this all together:

                  <pre class="brush: python">
                    X = np.array([ [0,0,1] ])
                    y = np.array([ [1] ]).T
                    W = np.random.randn(3, 1)
                    for i in range(10000):
                        A = np.dot(X, W)
                        P = sigmoid(A)
                        L = 0.5 * (y - P) ** 2
                        dLdP = -1.0 * (y - P)
                        dPdA = sigmoid(A) * (1.0 - sigmoid(A))
                        dLdA = dLdP * dPdA
                        dAdW = X.T
                        dLdW = np.dot(dAdW, dLdA)
                        W -= 0.5 * dLdW
                    </pre>

                    <p> Congratulations: this is an excellent start to understanding neural nets. Like any good tutorial,
                      it hopefully answered some questions, but also gave you the confidence to start asking more questions.
                      Next week, we'll dwell further on this simple example, asking:
                      <ul>
                      <li>Does this "neural net" work? How can we tell? Continuing the theme of being precise, what <em>exactly</em>
                        does it mean for a neural net to work?</li>
                      <li>How can we extend this understanding of neural networks as compositions of functions to understand
                      more complex neural networks? As we will see soon, the same techniques apply.</li>
                      </ul>

</body>

</html>
